leaderboard_robustness=[
    {
        "Model": "Baichuan-13b",
        "AdvGlue": 0.363,
        "AdvInstruction": 93.99,
        "OOD detection": 0.004,
        "OOD generalization": 0.539,
        "AdvGlue_rank": 6,
        "AdvInstruction_rank": 13,
        "OOD_detection_rank": 16,
        "OOD_generalization_rank": 16
    },
    {
        "Model": "ChatGLM2",
        "AdvGlue": 0.254,
        "AdvInstruction": 94.37,
        "OOD detection": 0.627,
        "OOD generalization": 0.778,
        "AdvGlue_rank": 10,
        "AdvInstruction_rank": 11,
        "OOD_detection_rank": 6,
        "OOD_generalization_rank": 12
    },
    {
        "Model": "Vicuna-13b",
        "AdvGlue": 0.18,
        "AdvInstruction": 96.01,
        "OOD detection": 0.635,
        "OOD generalization": 0.839,
        "AdvGlue_rank": 12,
        "AdvInstruction_rank": 6,
        "OOD_detection_rank": 5,
        "OOD_generalization_rank": 7
    },
    {
        "Model": "Vicuna-7b",
        "AdvGlue": 0.072,
        "AdvInstruction": 88.77,
        "OOD detection": 0.49,
        "OOD generalization": 0.753,
        "AdvGlue_rank": 16,
        "AdvInstruction_rank": 16,
        "OOD_detection_rank": 9,
        "OOD_generalization_rank": 14
    },
    {
        "Model": "Vicuna-33b",
        "AdvGlue": 0.219,
        "AdvInstruction": 95.97,
        "OOD detection": 0.685,
        "OOD generalization": 0.785,
        "AdvGlue_rank": 11,
        "AdvInstruction_rank": 7,
        "OOD_detection_rank": 3,
        "OOD_generalization_rank": 11
    },
    {
        "Model": "Llama2-7b",
        "AdvGlue": 0.374,
        "AdvInstruction": 96.68,
        "OOD detection": 0.465,
        "OOD generalization": 0.777,
        "AdvGlue_rank": 5,
        "AdvInstruction_rank": 3,
        "OOD_detection_rank": 10,
        "OOD_generalization_rank": 13
    },
    {
        "Model": "Llama2-13b",
        "AdvGlue": 0.306,
        "AdvInstruction": 96.48,
        "OOD detection": 0.432,
        "OOD generalization": 0.884,
        "AdvGlue_rank": 9,
        "AdvInstruction_rank": 4,
        "OOD_detection_rank": 12,
        "OOD_generalization_rank": 2
    },
    {
        "Model": "Koala-13b",
        "AdvGlue": 0.116,
        "AdvInstruction": 94.05,
        "OOD detection": 0.552,
        "OOD generalization": 0.584,
        "AdvGlue_rank": 15,
        "AdvInstruction_rank": 12,
        "OOD_detection_rank": 7,
        "OOD_generalization_rank": 15
    },
    {
        "Model": "Oasst-12b",
        "AdvGlue": 0.143,
        "AdvInstruction": 93.68,
        "OOD detection": 0.398,
        "OOD generalization": 0.883,
        "AdvGlue_rank": 14,
        "AdvInstruction_rank": 14,
        "OOD_detection_rank": 14,
        "OOD_generalization_rank": 3
    },
    {
        "Model": "Wizardlm-13b",
        "AdvGlue": 0.152,
        "AdvInstruction": 95.02,
        "OOD detection": 0.643,
        "OOD generalization": 0.871,
        "AdvGlue_rank": 13,
        "AdvInstruction_rank": 10,
        "OOD_detection_rank": 4,
        "OOD_generalization_rank": 5
    },
    {
        "Model": "ERNIE",
        "AdvGlue": 0.408,
        "AdvInstruction": 90.99,
        "OOD detection": 0.548,
        "OOD generalization": 0.795,
        "AdvGlue_rank": 4,
        "AdvInstruction_rank": 15,
        "OOD_detection_rank": 8,
        "OOD_generalization_rank": 10
    },
    {
        "Model": "ChatGPT",
        "AdvGlue": 0.326,
        "AdvInstruction": 97.42,
        "OOD detection": 0.697,
        "OOD generalization": 0.867,
        "AdvGlue_rank": 8,
        "AdvInstruction_rank": 2,
        "OOD_detection_rank": 2,
        "OOD_generalization_rank": 6
    },
    {
        "Model": "GPT-4",
        "AdvGlue": 0.591,
        "AdvInstruction": 96.36,
        "OOD detection": 0.805,
        "OOD generalization": 0.923,
        "AdvGlue_rank": 2,
        "AdvInstruction_rank": 5,
        "OOD_detection_rank": 1,
        "OOD_generalization_rank": 1
    },
    {
        "Model": "Llama2-70b",
        "AdvGlue": 0.471,
        "AdvInstruction": 97.64,
        "OOD detection": 0.461,
        "OOD generalization": 0.873,
        "AdvGlue_rank": 3,
        "AdvInstruction_rank": 1,
        "OOD_detection_rank": 11,
        "OOD_generalization_rank": 4
    },
    {
        "Model": "Mistral-7b",
        "AdvGlue": 0.331,
        "AdvInstruction": 95.76,
        "OOD detection": 0.407,
        "OOD generalization": 0.822,
        "AdvGlue_rank": 7,
        "AdvInstruction_rank": 8,
        "OOD_detection_rank": 13,
        "OOD_generalization_rank": 8
    },
    {
        "Model": "PaLM 2",
        "AdvGlue": 0.607,
        "AdvInstruction": 95.41,
        "OOD detection": 0.104,
        "OOD generalization": 0.822,
        "AdvGlue_rank": 1,
        "AdvInstruction_rank": 9,
        "OOD_detection_rank": 15,
        "OOD_generalization_rank": 8
    }
]

leaderboard_privacy=[
    {
        "Model": "Baichuan-13b",
        "Normal": 0.082,
        "Aug": 0.225,
        "RtA": 0.65,
        "TD": 0.06,
        "CD": 0.11,
        "Cor.": 0.567,
        "Normal_rank": 16,
        "Aug_rank": 16,
        "RtA_rank": 8,
        "TD_rank": 11,
        "CD_rank": 12,
        "Cor_rank": 4
    },
    {
        "Model": "ChatGLM2",
        "Normal": 0.789,
        "Aug": 0.993,
        "RtA": 0.64,
        "TD": 0.13,
        "CD": 0.22,
        "Cor.": 0.248,
        "Normal_rank": 9,
        "Aug_rank": 11,
        "RtA_rank": 9,
        "TD_rank": 8,
        "CD_rank": 9,
        "Cor_rank": 11
    },
    {
        "Model": "ChatGPT",
        "Normal": 0.714,
        "Aug": 1.0,
        "RtA": 0.28,
        "TD": 0.3,
        "CD": 0.35,
        "Cor.": 0.665,
        "Normal_rank": 12,
        "Aug_rank": 1,
        "RtA_rank": 14,
        "TD_rank": 2,
        "CD_rank": 2,
        "Cor_rank": 1
    },
    {
        "Model": "ERNIE",
        "Normal": 0.911,
        "Aug": 0.993,
        "RtA": 0.89,
        "TD": 0.01,
        "CD": 0.02,
        "Cor.": 0.473,
        "Normal_rank": 6,
        "Aug_rank": 11,
        "RtA_rank": 3,
        "TD_rank": 14,
        "CD_rank": 16,
        "Cor_rank": 6
    },
    {
        "Model": "Koala-13b",
        "Normal": 0.718,
        "Aug": 0.982,
        "RtA": 0.27,
        "TD": 0.21,
        "CD": 0.32,
        "Cor.": 0.185,
        "Normal_rank": 11,
        "Aug_rank": 13,
        "RtA_rank": 15,
        "TD_rank": 5,
        "CD_rank": 4,
        "Cor_rank": 12
    },
    {
        "Model": "Llama2-7b",
        "Normal": 1.0,
        "Aug": 1.0,
        "RtA": 0.94,
        "TD": 0.02,
        "CD": 0.09,
        "Cor.": 0.101,
        "Normal_rank": 1,
        "Aug_rank": 1,
        "RtA_rank": 2,
        "TD_rank": 13,
        "CD_rank": 13,
        "Cor_rank": 15
    },
    {
        "Model": "Llama2-13b",
        "Normal": 1.0,
        "Aug": 1.0,
        "RtA": 0.98,
        "TD": 0.0,
        "CD": 0.03,
        "Cor.": 0.17,
        "Normal_rank": 1,
        "Aug_rank": 1,
        "RtA_rank": 1,
        "TD_rank": 16,
        "CD_rank": 15,
        "Cor_rank": 14
    },
    {
        "Model": "Oasst-12b",
        "Normal": 0.389,
        "Aug": 0.886,
        "RtA": 0.82,
        "TD": 0.01,
        "CD": 0.13,
        "Cor.": -0.161,
        "Normal_rank": 14,
        "Aug_rank": 15,
        "RtA_rank": 6,
        "TD_rank": 14,
        "CD_rank": 11,
        "Cor_rank": 16
    },
    {
        "Model": "Vicuna-7b",
        "Normal": 0.836,
        "Aug": 0.982,
        "RtA": 0.62,
        "TD": 0.17,
        "CD": 0.28,
        "Cor.": 0.373,
        "Normal_rank": 7,
        "Aug_rank": 13,
        "RtA_rank": 11,
        "TD_rank": 7,
        "CD_rank": 7,
        "Cor_rank": 9
    },
    {
        "Model": "Vicuna-13b",
        "Normal": 0.829,
        "Aug": 1.0,
        "RtA": 0.64,
        "TD": 0.21,
        "CD": 0.31,
        "Cor.": 0.367,
        "Normal_rank": 8,
        "Aug_rank": 1,
        "RtA_rank": 9,
        "TD_rank": 5,
        "CD_rank": 5,
        "Cor_rank": 10
    },
    {
        "Model": "Vicuna-33b",
        "Normal": 0.743,
        "Aug": 1.0,
        "RtA": 0.32,
        "TD": 0.28,
        "CD": 0.3,
        "Cor.": 0.442,
        "Normal_rank": 10,
        "Aug_rank": 1,
        "RtA_rank": 13,
        "TD_rank": 3,
        "CD_rank": 6,
        "Cor_rank": 8
    },
    {
        "Model": "Wizardlm-13b",
        "Normal": 0.979,
        "Aug": 1.0,
        "RtA": 0.87,
        "TD": 0.08,
        "CD": 0.35,
        "Cor.": 0.183,
        "Normal_rank": 5,
        "Aug_rank": 1,
        "RtA_rank": 4,
        "TD_rank": 9,
        "CD_rank": 2,
        "Cor_rank": 13
    },
    {
        "Model": "GPT-4",
        "Normal": 0.982,
        "Aug": 1.0,
        "RtA": 0.41,
        "TD": 0.33,
        "CD": 0.36,
        "Cor.": 0.634,
        "Normal_rank": 4,
        "Aug_rank": 1,
        "RtA_rank": 12,
        "TD_rank": 1,
        "CD_rank": 1,
        "Cor_rank": 2
    },
    {
        "Model": "Llama2-70b",
        "Normal": 1.0,
        "Aug": 1.0,
        "RtA": 0.86,
        "TD": 0.07,
        "CD": 0.22,
        "Cor.": 0.484,
        "Normal_rank": 1,
        "Aug_rank": 1,
        "RtA_rank": 5,
        "TD_rank": 10,
        "CD_rank": 9,
        "Cor_rank": 5
    },
    {
        "Model": "Mistral-7b",
        "Normal": 0.654,
        "Aug": 1.0,
        "RtA": 0.71,
        "TD": 0.04,
        "CD": 0.08,
        "Cor.": 0.469,
        "Normal_rank": 13,
        "Aug_rank": 1,
        "RtA_rank": 7,
        "TD_rank": 12,
        "CD_rank": 14,
        "Cor_rank": 7
    },
    {
        "Model": "PaLM 2",
        "Normal": 0.089,
        "Aug": 1.0,
        "RtA": 0.1,
        "TD": 0.26,
        "CD": 0.28,
        "Cor.": 0.572,
        "Normal_rank": 15,
        "Aug_rank": 1,
        "RtA_rank": 16,
        "TD_rank": 4,
        "CD_rank": 7,
        "Cor_rank": 3
    }
]