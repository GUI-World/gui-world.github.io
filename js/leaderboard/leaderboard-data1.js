privacy=[{"Model": "Baichuan-13b", "Normal": 0.082, "Aug": 0.225, "RtA": 0.65, "TD": 0.06, "CD": 0.11, "Cor.": 0.567}, {"Model": "ChatGLM2", "Normal": 0.789, "Aug": 0.993, "RtA": 0.64, "TD": 0.13, "CD": 0.22, "Cor.": 0.248}, {"Model": "ChatGPT", "Normal": 0.714, "Aug": 1.0, "RtA": 0.28, "TD": 0.3, "CD": 0.35, "Cor.": 0.665}, {"Model": "ERNIE", "Normal": 0.911, "Aug": 0.993, "RtA": 0.89, "TD": 0.01, "CD": 0.02, "Cor.": 0.473}, {"Model": "Koala-13b", "Normal": 0.718, "Aug": 0.982, "RtA": 0.27, "TD": 0.21, "CD": 0.32, "Cor.": 0.185}, {"Model": "Llama2-7b", "Normal": 1.0, "Aug": 1.0, "RtA": 0.94, "TD": 0.02, "CD": 0.09, "Cor.": 0.101}, {"Model": "Llama2-13b", "Normal": 1.0, "Aug": 1.0, "RtA": 0.98, "TD": 0.0, "CD": 0.03, "Cor.": 0.17}, {"Model": "Oasst-12b", "Normal": 0.389, "Aug": 0.886, "RtA": 0.82, "TD": 0.01, "CD": 0.13, "Cor.": -0.161}, {"Model": "Vicuna-7b", "Normal": 0.836, "Aug": 0.982, "RtA": 0.62, "TD": 0.17, "CD": 0.28, "Cor.": 0.373}, {"Model": "Vicuna-13b", "Normal": 0.829, "Aug": 1.0, "RtA": 0.64, "TD": 0.21, "CD": 0.31, "Cor.": 0.367}, {"Model": "Vicuna-33b", "Normal": 0.743, "Aug": 1.0, "RtA": 0.32, "TD": 0.28, "CD": 0.3, "Cor.": 0.442}, {"Model": "Wizardlm-13b", "Normal": 0.979, "Aug": 1.0, "RtA": 0.87, "TD": 0.08, "CD": 0.35, "Cor.": 0.183}, {"Model": "GPT-4", "Normal": 0.982, "Aug": 1.0, "RtA": 0.41, "TD": 0.33, "CD": 0.36, "Cor.": 0.634}, {"Model": "Llama2-70b", "Normal": 1.0, "Aug": 1.0, "RtA": 0.86, "TD": 0.07, "CD": 0.22, "Cor.": 0.484}, {"Model": "Mistral-7b", "Normal": 0.654, "Aug": 1.0, "RtA": 0.71, "TD": 0.04, "CD": 0.08, "Cor.": 0.469}, {"Model": "PaLM 2", "Normal": 0.089, "Aug": 1.0, "RtA": 0.1, "TD": 0.26, "CD": 0.28, "Cor.": 0.572}]
robustness=[{"Model": "Baichuan-13b", "AdvGlue": 0.363, "AdvInstruction": 93.99, "OOD detection": 0.004, "OOD generalization": 0.539}, {"Model": "ChatGLM2", "AdvGlue": 0.254, "AdvInstruction": 94.37, "OOD detection": 0.627, "OOD generalization": 0.778}, {"Model": "Vicuna-13b", "AdvGlue": 0.18, "AdvInstruction": 96.01, "OOD detection": 0.635, "OOD generalization": 0.839}, {"Model": "Vicuna-7b", "AdvGlue": 0.072, "AdvInstruction": 88.77, "OOD detection": 0.49, "OOD generalization": 0.753}, {"Model": "Vicuna-33b", "AdvGlue": 0.219, "AdvInstruction": 95.97, "OOD detection": 0.685, "OOD generalization": 0.785}, {"Model": "Llama2-7b", "AdvGlue": 0.374, "AdvInstruction": 96.68, "OOD detection": 0.465, "OOD generalization": 0.777}, {"Model": "Llama2-13b", "AdvGlue": 0.306, "AdvInstruction": 96.48, "OOD detection": 0.432, "OOD generalization": 0.884}, {"Model": "Koala-13b", "AdvGlue": 0.116, "AdvInstruction": 94.05, "OOD detection": 0.552, "OOD generalization": 0.584}, {"Model": "Oasst-12b", "AdvGlue": 0.143, "AdvInstruction": 93.68, "OOD detection": 0.398, "OOD generalization": 0.883}, {"Model": "Wizardlm-13b", "AdvGlue": 0.152, "AdvInstruction": 95.02, "OOD detection": 0.643, "OOD generalization": 0.871}, {"Model": "ERNIE", "AdvGlue": 0.408, "AdvInstruction": 90.99, "OOD detection": 0.548, "OOD generalization": 0.795}, {"Model": "ChatGPT", "AdvGlue": 0.326, "AdvInstruction": 97.42, "OOD detection": 0.697, "OOD generalization": 0.867}, {"Model": "GPT-4", "AdvGlue": 0.591, "AdvInstruction": 96.36, "OOD detection": 0.805, "OOD generalization": 0.923}, {"Model": "Llama2-70b", "AdvGlue": 0.471, "AdvInstruction": 97.64, "OOD detection": 0.461, "OOD generalization": 0.873}, {"Model": "Mistral-7b", "AdvGlue": 0.331, "AdvInstruction": 95.76, "OOD detection": 0.407, "OOD generalization": 0.822}, {"Model": "PaLM 2", "AdvGlue": 0.607, "AdvInstruction": 95.41, "OOD detection": 0.104, "OOD generalization": 0.822}]
ethics=[{"Model": " GPT-4", "Social Chemistry 101 Acc": 0.674, "ETHICS Acc": 0.674, "MoralChoice Acc": 1.0, "MoralChoice RtA": 0.669, "Emotional Acc": 0.945}, {"Model": "PaLM 2", "Social Chemistry 101 Acc": 0.67, "ETHICS Acc": 0.602, "MoralChoice Acc": 0.993, "MoralChoice RtA": 0.429, "Emotional Acc": 0.935}, {"Model": "chatgpt", "Social Chemistry 101 Acc": 0.654, "ETHICS Acc": 0.668, "MoralChoice Acc": 1.0, "MoralChoice RtA": 0.682, "Emotional Acc": 0.915}, {"Model": "ernie", "Social Chemistry 101 Acc": 0.651, "ETHICS Acc": 0.601, "MoralChoice Acc": 0.993, "MoralChoice RtA": 0.953, "Emotional Acc": 0.875}, {"Model": "llama2-70b", "Social Chemistry 101 Acc": 0.653, "ETHICS Acc": 0.598, "MoralChoice Acc": 0.991, "MoralChoice RtA": 0.999, "Emotional Acc": 0.875}, {"Model": "wizardlm-13b", "Social Chemistry 101 Acc": 0.652, "ETHICS Acc": 0.655, "MoralChoice Acc": 0.991, "MoralChoice RtA": 0.85, "Emotional Acc": 0.81}, {"Model": "Mistral-7b", "Social Chemistry 101 Acc": 0.647, "ETHICS Acc": 0.66, "MoralChoice Acc": 0.987, "MoralChoice RtA": 0.86, "Emotional Acc": 0.81}, {"Model": "chatglm2", "Social Chemistry 101 Acc": 0.588, "ETHICS Acc": 0.613, "MoralChoice Acc": 0.942, "MoralChoice RtA": 0.651, "Emotional Acc": 0.765}, {"Model": "vicuna-13b", "Social Chemistry 101 Acc": 0.518, "ETHICS Acc": 0.633, "MoralChoice Acc": 0.905, "MoralChoice RtA": 0.99, "Emotional Acc": 0.75}, {"Model": "llama2-13b", "Social Chemistry 101 Acc": 0.619, "ETHICS Acc": 0.614, "MoralChoice Acc": 0.962, "MoralChoice RtA": 0.999, "Emotional Acc": 0.735}, {"Model": "vicuna-33b", "Social Chemistry 101 Acc": 0.668, "ETHICS Acc": 0.643, "MoralChoice Acc": 0.985, "MoralChoice RtA": 0.938, "Emotional Acc": 0.725}, {"Model": "baichuan-13b", "Social Chemistry 101 Acc": 0.571, "ETHICS Acc": 0.592, "MoralChoice Acc": 0.789, "MoralChoice RtA": 0.622, "Emotional Acc": 0.705}, {"Model": "llama2-7b", "Social Chemistry 101 Acc": 0.609, "ETHICS Acc": 0.657, "MoralChoice Acc": 0.92, "MoralChoice RtA": 0.999, "Emotional Acc": 0.63}, {"Model": "vicuna-7b", "Social Chemistry 101 Acc": 0.594, "ETHICS Acc": 0.609, "MoralChoice Acc": 0.594, "MoralChoice RtA": 0.944, "Emotional Acc": 0.485}, {"Model": "koala-13b", "Social Chemistry 101 Acc": 0.546, "ETHICS Acc": 0.465, "MoralChoice Acc": 0.924, "MoralChoice RtA": 0.872, "Emotional Acc": 0.34}, {"Model": "oasst-12b", "Social Chemistry 101 Acc": 0.539, "ETHICS Acc": 0.492, "MoralChoice Acc": 0.505, "MoralChoice RtA": 0.631, "Emotional Acc": 0.105}]
truthfulness_V2=[{"Model": "Table 7. Internal ", "ChatGPT": 0.288, "GPT-4": 0.417, "ChatGLM2": 0.127, "Vicuna-33b": 0.261, "Vicuna-13b": 0.18, "Vicuna-7b": 0.132, "Llama2-70b": 0.313, "Llama2-13b": 0.235, "Llama2-7b": 0.203, "Wizardlm-13b": 0.19, "Koala-13b": 0.145, "Baichuan-13b": 0.17, "Oasst-12b": 0.101, "ERNIE": 0.255, "Mistral-7b": 0.341, "PaLM2": 0.284}, {"Model": "Table 7. Internal Rank", "ChatGPT": 4.0, "GPT-4": 1.0, "ChatGLM2": 15.0, "Vicuna-33b": 6.0, "Vicuna-13b": 11.0, "Vicuna-7b": 14.0, "Llama2-70b": 3.0, "Llama2-13b": 8.0, "Llama2-7b": 9.0, "Wizardlm-13b": 10.0, "Koala-13b": 13.0, "Baichuan-13b": 12.0, "Oasst-12b": 16.0, "ERNIE": 7.0, "Mistral-7b": 2.0, "PaLM2": 5.0}, {"Model": "Table 9. External", "ChatGPT": 0.726, "GPT-4": 0.793, "ChatGLM2": 0.542, "Vicuna-33b": 0.726, "Vicuna-13b": 0.623, "Vicuna-7b": 0.581, "Llama2-70b": 0.721, "Llama2-13b": 0.722, "Llama2-7b": 0.638, "Wizardlm-13b": 0.574, "Koala-13b": 0.553, "Baichuan-13b": 0.622, "Oasst-12b": 0.534, "ERNIE": 0.689, "Mistral-7b": 0.687, "PaLM2": 0.532}, {"Model": "Table 9. External Rank", "ChatGPT": 2.0, "GPT-4": 1.0, "ChatGLM2": 14.0, "Vicuna-33b": 2.0, "Vicuna-13b": 9.0, "Vicuna-7b": 11.0, "Llama2-70b": 5.0, "Llama2-13b": 4.0, "Llama2-7b": 8.0, "Wizardlm-13b": 12.0, "Koala-13b": 13.0, "Baichuan-13b": 10.0, "Oasst-12b": 15.0, "ERNIE": 6.0, "Mistral-7b": 7.0, "PaLM2": 16.0}, {"Model": "Table 10. Hallucination", "ChatGPT": 0.529, "GPT-4": 0.516, "ChatGLM2": 0.542, "Vicuna-33b": 0.423, "Vicuna-13b": 0.403, "Vicuna-7b": 0.347, "Llama2-70b": 0.402, "Llama2-13b": 0.404, "Llama2-7b": 0.396, "Wizardlm-13b": 0.356, "Koala-13b": 0.451, "Baichuan-13b": 0.306, "Oasst-12b": 0.418, "ERNIE": 0.515, "Mistral-7b": 0.458, "PaLM2": 0.379}, {"Model": "Table 10. Hallucination Rank", "ChatGPT": 2.0, "GPT-4": 3.0, "ChatGLM2": 1.0, "Vicuna-33b": 7.0, "Vicuna-13b": 9.0, "Vicuna-7b": 15.0, "Llama2-70b": 10.0, "Llama2-13b": 8.0, "Llama2-7b": 12.0, "Wizardlm-13b": 14.0, "Koala-13b": 6.0, "Baichuan-13b": 16.0, "Oasst-12b": 7.0, "ERNIE": 4.0, "Mistral-7b": 5.0, "PaLM2": 13.0}, {"Model": "Table 13. Persona Sycophancy", "ChatGPT": 0.039, "GPT-4": 0.029, "ChatGLM2": 0.036, "Vicuna-33b": 0.038, "Vicuna-13b": 0.036, "Vicuna-7b": 0.03, "Llama2-70b": 0.043, "Llama2-13b": 0.032, "Llama2-7b": 0.035, "Wizardlm-13b": 0.025, "Koala-13b": 0.04, "Baichuan-13b": 0.032, "Oasst-12b": 0.031, "ERNIE": 0.019, "Mistral-7b": 0.035, "PaLM2": 0.028}, {"Model": "Table 13. Persona Rank", "ChatGPT": 3.0, "GPT-4": 13.0, "ChatGLM2": 5.0, "Vicuna-33b": 4.0, "Vicuna-13b": 5.0, "Vicuna-7b": 12.0, "Llama2-70b": 1.0, "Llama2-13b": 9.0, "Llama2-7b": 7.0, "Wizardlm-13b": 15.0, "Koala-13b": 2.0, "Baichuan-13b": 9.0, "Oasst-12b": 11.0, "ERNIE": 16.0, "Mistral-7b": 7.0, "PaLM2": 4.0}, {"Model": "Table 13. Preference Sycophancy", "ChatGPT": 0.257, "GPT-4": 0.296, "ChatGLM2": 0.432, "Vicuna-33b": 0.458, "Vicuna-13b": 0.375, "Vicuna-7b": 0.395, "Llama2-70b": 0.468, "Llama2-13b": 0.571, "Llama2-7b": 0.587, "Wizardlm-13b": 0.385, "Koala-13b": 0.5, "Baichuan-13b": 0.286, "Oasst-12b": 0.436, "ERNIE": 0.312, "Mistral-7b": 0.293, "PaLM2": 0.581}, {"Model": "Table 13. Preference Rank", "ChatGPT": 1.0, "GPT-4": 4.0, "ChatGLM2": 9.0, "Vicuna-33b": 11.0, "Vicuna-13b": 6.0, "Vicuna-7b": 8.0, "Llama2-70b": 12.0, "Llama2-13b": 14.0, "Llama2-7b": 16.0, "Wizardlm-13b": 7.0, "Koala-13b": 13.0, "Baichuan-13b": 2.0, "Oasst-12b": 10.0, "ERNIE": 5.0, "Mistral-7b": 3.0, "PaLM2": 15.0}, {"Model": "Table 15. Adv Factuality", "ChatGPT": 0.708, "GPT-4": 0.813, "ChatGLM2": 0.349, "Vicuna-33b": 0.699, "Vicuna-13b": 0.665, "Vicuna-7b": 0.469, "Llama2-70b": 0.794, "Llama2-13b": 0.78, "Llama2-7b": 0.718, "Wizardlm-13b": 0.794, "Koala-13b": 0.435, "Baichuan-13b": 0.44, "Oasst-12b": 0.221, "ERNIE": 0.407, "Mistral-7b": 0.426, "PaLM2": 0.273}, {"Model": "Table 15. Adv Factuality Rank", "ChatGPT": 6.0, "GPT-4": 1.0, "ChatGLM2": 14.0, "Vicuna-33b": 7.0, "Vicuna-13b": 8.0, "Vicuna-7b": 9.0, "Llama2-70b": 2.0, "Llama2-13b": 4.0, "Llama2-7b": 5.0, "Wizardlm-13b": 2.0, "Koala-13b": 11.0, "Baichuan-13b": 10.0, "Oasst-12b": 16.0, "ERNIE": 13.0, "Mistral-7b": 12.0, "PaLM2": 15.0}]
safety=[{"Model": "Llama2-13b", "Jailbreak(\u2191)": 0.959, "Toxicity(\u2193)": 0.205, "Misuse(\u2191)": 0.963, "Exaggerated Safety(\u2193)": 0.55}, {"Model": "Llama2-70b", "Jailbreak(\u2191)": 0.974, "Toxicity(\u2193)": 0.248, "Misuse(\u2191)": 0.956, "Exaggerated Safety(\u2193)": 0.315}, {"Model": "Llama2-7b", "Jailbreak(\u2191)": 0.945, "Toxicity(\u2193)": 0.191, "Misuse(\u2191)": 0.943, "Exaggerated Safety(\u2193)": 0.49}, {"Model": "GPT-4", "Jailbreak(\u2191)": 0.914, "Toxicity(\u2193)": 0.386, "Misuse(\u2191)": 0.924, "Exaggerated Safety(\u2193)": 0.085}, {"Model": "ChatGPT", "Jailbreak(\u2191)": 0.898, "Toxicity(\u2193)": 0.352, "Misuse(\u2191)": 0.91, "Exaggerated Safety(\u2193)": 0.15}, {"Model": "ERNIE", "Jailbreak(\u2191)": 0.949, "Toxicity(\u2193)": 0.072, "Misuse(\u2191)": 0.899, "Exaggerated Safety(\u2193)": 0.385}, {"Model": "Wizardlm-13b", "Jailbreak(\u2191)": 0.865, "Toxicity(\u2193)": 0.183, "Misuse(\u2191)": 0.883, "Exaggerated Safety(\u2193)": 0.06}, {"Model": "Vicuna-13b", "Jailbreak(\u2191)": 0.781, "Toxicity(\u2193)": 0.374, "Misuse(\u2191)": 0.848, "Exaggerated Safety(\u2193)": 0.095}, {"Model": "ChatGLM2", "Jailbreak(\u2191)": 0.845, "Toxicity(\u2193)": 0.141, "Misuse(\u2191)": 0.819, "Exaggerated Safety(\u2193)": 0.15}, {"Model": "Koala-13b", "Jailbreak(\u2191)": 0.691, "Toxicity(\u2193)": 0.237, "Misuse(\u2191)": 0.738, "Exaggerated Safety(\u2193)": 0.045}, {"Model": "Vicuna-33b", "Jailbreak(\u2191)": 0.585, "Toxicity(\u2193)": 0.294, "Misuse(\u2191)": 0.735, "Exaggerated Safety(\u2193)": 0.035}, {"Model": "Mistral-7b", "Jailbreak(\u2191)": 0.59, "Toxicity(\u2193)": 0.262, "Misuse(\u2191)": 0.709, "Exaggerated Safety(\u2193)": 0.46}, {"Model": "Oasst-12b", "Jailbreak(\u2191)": 0.69, "Toxicity(\u2193)": 0.154, "Misuse(\u2191)": 0.583, "Exaggerated Safety(\u2193)": 0.05}, {"Model": "Vicuna-7b", "Jailbreak(\u2191)": 0.596, "Toxicity(\u2193)": 0.213, "Misuse(\u2191)": 0.565, "Exaggerated Safety(\u2193)": 0.09}, {"Model": "PaLM 2", "Jailbreak(\u2191)": 0.486, "Toxicity(\u2193)": 0.317, "Misuse(\u2191)": 0.473, "Exaggerated Safety(\u2193)": 0.377}, {"Model": "Baichuan-13b", "Jailbreak(\u2191)": 0.25, "Toxicity(\u2193)": 0.112, "Misuse(\u2191)": 0.114, "Exaggerated Safety(\u2193)": 0.19}]
